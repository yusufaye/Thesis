\chapter*{Abstract}

Edge computing has emerged as a transformative paradigm for real-time video analytics, offering low-latency processing by relocating computation closer to data sources. This shift is especially critical in domains such as public safety, traffic management, and autonomous systems, where responsiveness and bandwidth efficiency are crucial. Yet, edge environments are inherently resource-constrained and must contend with dynamic workloads, particularly when incorporating mobile cameras. These cameras provide valuable, timely perspectives but introduce unpredictability in data volume and scene composition, challenging traditional analytics pipelines and static workload distribution strategies. To address these constraints, this thesis presents {\videojam}, a decentralized load balancing framework that predicts short-term workload fluctuations and redistributes video traffic across edge nodes, enabling adaptive, low-latency performance without centralized coordination.

As edge systems evolve to support increasingly diverse \gls{ai} tasks, a second challenge arises, one that lies not in data flow but in model deployment. Indeed, colocating multiple~\glspl{dnn} on shared \glspl{gpu} has become a practical necessity, driven by the need to maximize limited computing resources while maintaining real-time inference. However, this necessity poses a fundamental challenge because when multiple models share the same hardware, their simultaneous execution can lead to competition for limited resources, resulting in slower performance and reduced reliability in meeting application requirements. Existing orchestration frameworks tend to adopt reactive or coarse-grained strategies, often neglecting the nuanced interactions that occur during model execution. To address this, this thesis introduces {\roomie}, a kernel-aware orchestration system that utilizes offline profiles and predicts interference among co-deployed models, enabling insightful placement decisions that preserve throughput and ensure consistent performance in resource-constrained deployments.

Together, these contributions advance the design of scalable, adaptive edge architectures capable of supporting high-fidelity video analytics across heterogeneous and dynamic deployments.

\chapter*{Résumé}

% Le traitement de données en périphérie (Edge Computing) est apparu comme un paradigme transformateur pour l'analyse vidéo en temps réel, offrant un traitement à faible latence en déplaçant les calculs plus près des sources de données. Ce changement est particulièrement critique dans des domaines tels que la sécurité publique, la gestion du trafic et les systèmes autonomes, où la réactivité et l'efficacité de la bande passante sont cruciales. Cependant, les environnements de calcul en périphérie sont intrinsèquement contraints en ressources et doivent faire face à des charges de travail dynamiques, en particulier lorsqu'ils intègrent des caméras mobiles. Ces caméras fournissent des perspectives précieuses et opportunes, mais  introduisent une imprévisibilité dans le volume de données et les éléments visuels présents dans les scènes filmées, ce qui remet en question les pipelines (chaines de traitement) d'analyse traditionnels et les stratégies de distribution de charge de travail statiques. Pour relever ces contraintes, cette thèse présente {\videojam}, une solution d'équilibrage de charge décentralisé qui prédit les fluctuations de charge de travail à court terme et redistribue le trafic vidéo entre les noeuds de calcul, permettant des performances adaptatives à faible latence sans coordination centralisée.

% Alors que les systèmes de calcul en périphérie évoluent pour prendre en charge des tâches d'intelligence artificielle de plus en plus diverses, un deuxième défi se pose, qui ne réside pas dans le flux de données mais dans le déploiement de modèles. En effet, la co-localisation de plusieurs réseaux de neurones profonds (\gls{dnn}) sur des accélérateurs de calcul (\gls{gpu}) partagés est désormais une pratique courante, motivée par la nécessité de maximiser les ressources de calcul limitées tout en maintenant une inférence en temps réel. Cependant, cette nécessité pose un défi fondamental car lorsque plusieurs modèles partagent les mêmes resources, leur exécution simultanée peut entraîner une concurrence pour des ressources limitées, entraînant une performance plus lente et une fiabilité réduite pour répondre aux exigences des applications. Les cadres d'orchestration existants ont tendance à adopter des stratégies réactives ou à gros grains, souvent en négligeant les interactions nuancées qui se produisent pendant l'exécution du modèle. Pour résoudre ce problème, cette thèse introduit {\roomie}, un système d'orchestration conscient du noyau (kernel) qui profile et anticipe les interférences entre les modèles déployés conjointement, permettant des décisions de placement éclairées qui préservent le débit et assurent des performances cohérentes dans les déploiements contraints en ressources.

% Ensemble, ces contributions avancent la conception d'architectures de calcul en périphérie scalables et adaptatives capables de prendre en charge une analyse vidéo haute fidélité sur des déploiements hétérogènes et dynamiques.

Le traitement de données en périphérie (Edge Computing) s'impose comme un paradigme transformateur pour l'analyse vidéo en temps réel, en rapprochant les calculs des sources de données afin de réduire la latence et d'améliorer l'efficacité de la bande passante. Cette évolution est particulièrement critique dans des domaines tels que la sécurité publique, la gestion du trafic ou les systèmes autonomes, où la réactivité est essentielle. Néanmoins, les environnements edge sont intrinsèquement contraints en ressources et doivent composer avec des charges de travail dynamiques, notamment lorsqu'ils intègrent des caméras mobiles. Ces dernières offrent des perspectives précieuses et opportunes, mais introduisent une forte imprévisibilité dans le volume de données et la composition des scènes, ce qui met à l'épreuve les pipelines d'analyse (processing pipelines) traditionnels ainsi que les stratégies statiques de distribution de charge. Pour relever ces défis, cette thèse présente {\videojam}, une solution d'équilibrage de charge décentralisé (decentralized load balancing) capable de prédire les fluctuations de charge à court terme et de redistribuer le trafic vidéo entre les nœuds edge, garantissant des performances adaptatives et à faible latence sans coordination centralisée.

Parallèlement, à mesure que les systèmes edge évoluent pour prendre en charge des tâches d'intelligence artificielle (IA) de plus en plus variées, un second défi apparaît, lié non pas au flux de données mais au déploiement des modèles. La co-localisation de plusieurs réseaux de neurones profonds (\acrshort{dnn} - \acrlong{dnn}) sur des accélérateurs graphiques (\acrshort{gpu} - \acrlong{gpu}) partagés est devenue une pratique courante, motivée par la nécessité de maximiser des ressources limitées tout en maintenant une inférence en temps réel. Cependant, cette co-exécution entraîne une concurrence pour les ressources matérielles, provoquant une dégradation des performances et une fiabilité réduite face aux exigences applicatives. Les cadres d'orchestration existants privilégient souvent des stratégies réactives ou grossières (coarse-grained), négligeant les interactions fines qui surviennent lors de l'exécution simultanée des modèles. Pour répondre à ce problème, cette thèse introduit {\roomie}, un système d'orchestration conscient du noyau (kernel-aware orchestration system) qui s'appuie sur des profils hors ligne (offline profiling) afin d'anticiper les interférences entre modèles co-déployés et de guider des décisions de placement optimisées, préservant ainsi le débit (goodput) et assurant des performances stables dans des environnements contraints.

Ces contributions renforcent la conception d'architectures edge scalables et adaptatives, capables de soutenir une analyse vidéo haute fidélité dans des déploiements hétérogènes et dynamiques.