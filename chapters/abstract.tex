\chapter*{Abstract}

Edge computing has emerged as a transformative paradigm for real-time video analytics, offering low-latency processing by relocating computation closer to data sources. This shift is especially critical in domains such as public safety, traffic management, and autonomous systems, where responsiveness and bandwidth efficiency are crucial. Yet, edge environments are inherently resource-constrained and must contend with dynamic workloads, particularly when incorporating mobile cameras. These cameras provide valuable, timely perspectives but introduce unpredictability in data volume and scene composition, challenging traditional analytics pipelines and static workload distribution strategies. To address these constraints, this thesis presents {\videojam}, a decentralized load balancing framework that predicts short-term workload fluctuations and redistributes video traffic across edge nodes, enabling adaptive, low-latency performance without centralized coordination.

As edge systems evolve to support increasingly diverse \gls{ai} tasks, a second challenge arises, one that lies not in data flow but in model deployment. Indeed, colocating multiple~\glspl{dnn} on shared \glspl{gpu} has become a practical necessity, driven by the need to maximize limited computing resources while maintaining real-time inference. However, this necessity poses a fundamental challenge because when multiple models share the same hardware, their simultaneous execution can lead to competition for limited resources, resulting in slower performance and reduced reliability in meeting application requirements. Existing orchestration frameworks tend to adopt reactive or coarse-grained strategies, often neglecting the nuanced interactions that occur during model execution. To address this, this thesis introduces {\roomie}, a kernel-aware orchestration system that profiles and anticipates interference between co-deployed models, enabling insightful placement decisions that preserve throughput and ensure consistent performance in resource-constrained deployments.

Together, these contributions advance the design of scalable, adaptive edge architectures capable of supporting high-fidelity video analytics across heterogeneous and dynamic deployments.

\chapter*{Résumé}

Le calcul en périphérie (edge computing) est apparu comme un paradigme transformateur pour l'analyse vidéo en temps réel, offrant un traitement à faible latence en déplaçant les calculs plus près des sources de données. Ce changement est particulièrement critique dans des domaines tels que la sécurité publique, la gestion du trafic et les systèmes autonomes, où la réactivité et l'efficacité de la bande passante sont cruciales. Cependant, les environnements de calcul en périphérie sont intrinsèquement contraints en ressources et doivent faire face à des charges de travail dynamiques, en particulier lorsqu'ils intègrent des caméras mobiles. Ces caméras fournissent des perspectives précieuses et opportunes, mais  introduisent une imprévisibilité dans le volume de données et les éléments visuels présents dans les scènes filmées, ce qui remet en question les pipelines (chaines de traitement) d'analyse traditionnels et les stratégies de distribution de charge de travail statiques. Pour relever ces contraintes, cette thèse présente {\videojam}, une solution d'équilibrage de charge décentralisé qui prédit les fluctuations de charge de travail à court terme et redistribue le trafic vidéo entre les noeuds de calcul, permettant des performances adaptatives à faible latence sans coordination centralisée.

Alors que les systèmes de calcul en périphérie évoluent pour prendre en charge des tâches d'intelligence artificielle de plus en plus diverses, un deuxième défi se pose, qui ne réside pas dans le flux de données mais dans le déploiement de modèles. En effet, la co-localisation de plusieurs réseaux de neurones profonds (\gls{dnn}) sur des accélérateurs de calcul (\gls{gpu}) partagés est désormais une pratique courante, motivée par la nécessité de maximiser les ressources de calcul limitées tout en maintenant une inférence en temps réel. Cependant, cette nécessité pose un défi fondamental car lorsque plusieurs modèles partagent les mêmes resources, leur exécution simultanée peut entraîner une concurrence pour des ressources limitées, entraînant une performance plus lente et une fiabilité réduite pour répondre aux exigences des applications. Les cadres d'orchestration existants ont tendance à adopter des stratégies réactives ou à gros grains, souvent en négligeant les interactions nuancées qui se produisent pendant l'exécution du modèle. Pour résoudre ce problème, cette thèse introduit {\roomie}, un système d'orchestration conscient du noyau qui profile et anticipe les interférences entre les modèles déployés conjointement, permettant des décisions de placement éclairées qui préservent le débit et assurent des performances cohérentes dans les déploiements contraints en ressources.

Ensemble, ces contributions avancent la conception d'architectures de calcul en périphérie scalables et adaptatives capables de prendre en charge une analyse vidéo haute fidélité sur des déploiements hétérogènes et dynamiques.