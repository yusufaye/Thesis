\chapter{Abstract}

% The rise of edge computing marks a pivotal shift in how data-intensive applications are deployed and scaled. By relocating computation closer to the data source, edge architectures offer a compelling solution to the latency and bandwidth constraints inherent in cloud-based systems. This shift is particularly transformative for live video analytics, where real-time responsiveness is critical across domains such as public safety, traffic management, and autonomous systems. Processing video streams locally enables faster decision-making and reduces the overhead of transmitting raw data to centralized servers. Yet, the promise of edge computing is tempered by its limitations—most notably, constrained computational resources and the complexity of managing dynamic workloads.

% Among the most promising yet challenging sources of video data are mobile cameras. Their ability to capture scenes from diverse and timely vantage points makes them invaluable for situational awareness. However, their unpredictable presence and constantly shifting perspectives introduce significant architectural challenges. Unlike fixed cameras, mobile feeds resist traditional background subtraction techniques and demand more resource-intensive models for object detection and tracking. Moreover, their intermittent connectivity and erratic data volumes undermine conventional workload balancing strategies, which rely on stable input patterns. To address these constraints, this thesis introduces VideoJam, a decentralized load balancing framework designed to adaptively distribute video processing tasks across edge nodes. By predicting short-term workload fluctuations and coordinating traffic offloading among neighboring components, VideoJam ensures low-latency performance and resilience to runtime changes—without requiring centralized control or static configurations.

% Beyond the challenge of managing video traffic, edge systems must also contend with the growing need to support multiple deep learning models simultaneously. As analytics pipelines become more complex, co-locating deep neural networks (DNNs) on shared GPUs is no longer optional—it is essential for maximizing limited resources and maintaining real-time performance. However, this necessity introduces a critical problem: interference at the GPU kernel level, where competing models can silently degrade each other's performance. Existing orchestration frameworks often overlook these low-level dynamics, resulting in unpredictable throughput and compromised service guarantees. To address this, the second contribution of this thesis presents Roomie, a kernel-aware orchestration system that profiles and anticipates interference patterns between co-deployed models. By leveraging these insights, Roomie enables intelligent placement decisions that preserve inference quality and ensure predictable behavior in resource-constrained edge environments.

% Together, VideoJam and Roomie form a cohesive response to the evolving demands of edge-based video analytics. This thesis not only advances the technical foundations of decentralized load balancing and model orchestration, but also reimagines how edge systems can remain agile, scalable, and intelligent in the face of dynamic data sources and constrained hardware. Through these contributions, it lays the groundwork for next-generation edge architectures capable of supporting real-time, high-fidelity analytics across heterogeneous environments.

% =========


Edge computing has emerged as a transformative paradigm for real-time video analytics, offering low-latency processing by relocating computation closer to data sources. This shift is especially critical in domains such as public safety, traffic management, and autonomous systems, where responsiveness and bandwidth efficiency are crucial. Yet, edge environments are inherently resource-constrained and must contend with dynamic workloads, particularly when incorporating mobile cameras. These cameras provide valuable, timely perspectives but introduce unpredictability in data volume and scene composition, challenging traditional analytics pipelines and static workload distribution strategies. To address these constraints, this thesis presents \textit{VideoJam}, a decentralized load balancing framework that predicts short-term workload fluctuations and redistributes video traffic across edge nodes, enabling adaptive, low-latency performance without centralized coordination.

As edge systems evolve to support increasingly diverse AI tasks, a second challenge arises, one that lies not in data flow but in model deployment. Indeed, colocating multiple deep neural networks (DNNs) on shared GPUs has become a practical necessity, driven by the need to maximize limited computing resources while maintaining real-time inference. However, this necessity poses a fundamental challenge because when multiple models share the same hardware, their simultaneous execution can lead to competition for limited resources, resulting in slower performance and reduced reliability in meeting application requirements. Existing orchestration frameworks tend to adopt reactive or coarse-grained strategies, often neglecting the nuanced interactions that occur during model execution. To address this, this thesis introduces \textit{Roomie}, a kernel-aware orchestration system that profiles and anticipates interference between co-deployed models, enabling insightful placement decisions that preserve throughput and ensure consistent performance in resource-constrained deployments.

Together, these contributions advance the design of scalable, adaptive edge architectures capable of supporting high-fidelity video analytics across heterogeneous and dynamic deployments.

\chapter{Résumé}

Le calcul en périphérie (Edge computing) est apparu comme un paradigme transformateur pour l'analyse vidéo en temps réel, offrant un traitement à faible latence en déplaçant les calculs plus près des sources de données. Ce changement est particulièrement critique dans des domaines tels que la sécurité publique, la gestion du trafic et les systèmes autonomes, où la réactivité et l'efficacité de la bande passante sont cruciales. Cependant, les environnements de calcul en périphérie sont intrinsèquement contraints en ressources et doivent faire face à des charges de travail dynamiques, en particulier lorsqu'ils intègrent des caméras mobiles. Ces caméras fournissent des perspectives précieuses et opportunes, mais  introduisent une imprévisibilité dans le volume de données et les éléments visuels présents dans les scènes filmées, ce qui remet en question les pipelines (chaines de traitement) d'analyse traditionnels et les stratégies de distribution de charge de travail statiques. Pour relever ces contraintes, cette thèse présente VideoJam, une solution d'équilibrage de charge décentralisé qui prédit les fluctuations de charge de travail à court terme et redistribue le trafic vidéo entre les noeuds de calcul, permettant des performances adaptatives à faible latence sans coordination centralisée.

Alors que les systèmes de calcul en périphérie évoluent pour prendre en charge des tâches d'intelligence artificielle de plus en plus diverses, un deuxième défi se pose, qui ne réside pas dans le flux de données mais dans le déploiement de modèles. En effet, la co-localisation de plusieurs réseaux de neurones profonds (DNN) sur des accélérateurs de calcul (GPU) partagés est désormais une pratique courante, motivée par la nécessité de maximiser les ressources de calcul limitées tout en maintenant une inférence en temps réel. Cependant, cette nécessité pose un défi fondamental car lorsque plusieurs modèles partagent les mêmes resources, leur exécution simultanée peut entraîner une concurrence pour des ressources limitées, entraînant une performance plus lente et une fiabilité réduite pour répondre aux exigences des applications. Les cadres d'orchestration existants ont tendance à adopter des stratégies réactives ou à gros grains, souvent en négligeant les interactions nuancées qui se produisent pendant l'exécution du modèle. Pour résoudre ce problème, cette thèse introduit Roomie, un système d'orchestration conscient du noyau qui profile et anticipe les interférences entre les modèles déployés conjointement, permettant des décisions de placement éclairées qui préservent le débit et assurent des performances cohérentes dans les déploiements contraints en ressources.

Ensemble, ces contributions avancent la conception d'architectures de calcul en périphérie scalables et adaptatives capables de prendre en charge une analyse vidéo haute fidélité sur des déploiements hétérogènes et dynamiques.