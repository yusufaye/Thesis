\chapter{Abstract}

% The rise of edge computing marks a pivotal shift in how data-intensive applications are deployed and scaled. By relocating computation closer to the data source, edge architectures offer a compelling solution to the latency and bandwidth constraints inherent in cloud-based systems. This shift is particularly transformative for live video analytics, where real-time responsiveness is critical across domains such as public safety, traffic management, and autonomous systems. Processing video streams locally enables faster decision-making and reduces the overhead of transmitting raw data to centralized servers. Yet, the promise of edge computing is tempered by its limitations—most notably, constrained computational resources and the complexity of managing dynamic workloads.

% Among the most promising yet challenging sources of video data are mobile cameras. Their ability to capture scenes from diverse and timely vantage points makes them invaluable for situational awareness. However, their unpredictable presence and constantly shifting perspectives introduce significant architectural challenges. Unlike fixed cameras, mobile feeds resist traditional background subtraction techniques and demand more resource-intensive models for object detection and tracking. Moreover, their intermittent connectivity and erratic data volumes undermine conventional workload balancing strategies, which rely on stable input patterns. To address these constraints, this thesis introduces VideoJam, a decentralized load balancing framework designed to adaptively distribute video processing tasks across edge nodes. By predicting short-term workload fluctuations and coordinating traffic offloading among neighboring components, VideoJam ensures low-latency performance and resilience to runtime changes—without requiring centralized control or static configurations.

% Beyond the challenge of managing video traffic, edge systems must also contend with the growing need to support multiple deep learning models simultaneously. As analytics pipelines become more complex, co-locating deep neural networks (DNNs) on shared GPUs is no longer optional—it is essential for maximizing limited resources and maintaining real-time performance. However, this necessity introduces a critical problem: interference at the GPU kernel level, where competing models can silently degrade each other's performance. Existing orchestration frameworks often overlook these low-level dynamics, resulting in unpredictable throughput and compromised service guarantees. To address this, the second contribution of this thesis presents Roomie, a kernel-aware orchestration system that profiles and anticipates interference patterns between co-deployed models. By leveraging these insights, Roomie enables intelligent placement decisions that preserve inference quality and ensure predictable behavior in resource-constrained edge environments.

% Together, VideoJam and Roomie form a cohesive response to the evolving demands of edge-based video analytics. This thesis not only advances the technical foundations of decentralized load balancing and model orchestration, but also reimagines how edge systems can remain agile, scalable, and intelligent in the face of dynamic data sources and constrained hardware. Through these contributions, it lays the groundwork for next-generation edge architectures capable of supporting real-time, high-fidelity analytics across heterogeneous environments.

% =========


Edge computing has emerged as a transformative paradigm for real-time video analytics, offering low-latency processing by relocating computation closer to data sources. This shift is especially critical in domains such as public safety, traffic management, and autonomous systems, where responsiveness and bandwidth efficiency are crucial. Yet, edge environments are inherently resource-constrained and must contend with dynamic workloads, particularly when incorporating mobile cameras. These cameras provide valuable, timely perspectives but introduce unpredictability in data volume and scene composition, challenging traditional analytics pipelines and static workload distribution strategies. To address these constraints, this thesis presents \textit{VideoJam}, a decentralized load balancing framework that predicts short-term workload fluctuations and redistributes video traffic across edge nodes, enabling adaptive, low-latency performance without centralized coordination.

As edge systems evolve to support increasingly diverse AI tasks, a second challenge arises, one that lies not in data flow but in model deployment. Indeed, colocating multiple deep neural networks (DNNs) on shared GPUs has become a practical necessity, driven by the need to maximize limited computing resources while maintaining real-time inference. However, this necessity poses a fundamental challenge because when multiple models share the same hardware, their simultaneous execution can lead to competition for limited resources, resulting in slower performance and reduced reliability in meeting application requirements. Existing orchestration frameworks tend to adopt reactive or coarse-grained strategies, often neglecting the nuanced interactions that occur during model execution. To address this, this thesis introduces \textit{Roomie}, a kernel-aware orchestration system that profiles and anticipates interference between co-deployed models, enabling insightful placement decisions that preserve throughput and ensure consistent performance in resource-constrained deployments.

Together, these contributions advance the design of scalable, adaptive edge architectures capable of supporting high-fidelity video analytics across heterogeneous and dynamic deployments.
