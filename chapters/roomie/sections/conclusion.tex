\section{Conclusion}

This work presents a comprehensive evaluation of {\roomie}, an interference-aware deployment strategy for \glspl{dnn} across modern GPU systems. Through experiments on cloud clusters, edge devices, and randomized deployment scenarios, {\roomie} consistently demonstrates robustness in sustaining high goodput while sharply reducing \gls{slo} violations compared to INFaaS and Usher. In cloud environments, it maintains responsiveness under heavy workloads, keeping violation rates below 10\% while INFaaS exceeds 30\% and Usher remains around 20\%. On edge devices, {\roomie} sustains violations near 9--10\%, whereas INFaaS rises above 40\% and Usher remains above 20\%, achieving up to 1.5$\times$ higher goodput than competing baselines despite severe resource constraints. Randomized deployment experiments further confirm scalability, with {\roomie} achieving near-optimal accuracy in approximately 90\% of trials even as concurrency increases and interference scenarios grow combinatorially.

While these results highlight {\roomie}'s strengths in preserving responsiveness under stress and scaling effectively without exhaustive enumeration, certain limitations remain. Its convergence time increases with the number of DNNs considered, which poses challenges for real-time adaptation. Moreover, its profiling strategy focuses primarily on kernel-level parameters and does not yet incorporate broader system-level factors such as PCIe bandwidth, cache behavior, SM availability, or inter-core latency. These aspects play an important role in interference dynamics and overall responsiveness, and addressing them will be essential for extending {\roomie} to production-scale deployments.

Taken together, these findings firmly establish {\roomie} as a practical and principled solution for multi-model inference, balancing efficiency and responsiveness across diverse deployment scenarios, while highlighting clear avenues for future refinement in scalability and system-level awareness.