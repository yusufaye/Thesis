\section{Related work}

In recent years, several techniques have been developed to improve the performance of video analytics applications~\cite{ibrahim2021survey,xu2023edge,hu2023edge}. Such a topic has been tackled from different perspectives, including the design of different data processing architectures~\cite{jain2020spatula,zhang2017live,jiang2018chameleon}, the improvement of pipelines' processing~\cite{fouladi2017encoding,chen2015glimpse,padmanabhan2021towards,padmanabhan2023gemel} and the privacy of the extracted data~\cite{cangialosi2022privid,poddar2020visor,wu2021pecam}. 

\paragraph{Architecture scaling.} Different approaches have been proposed to efficiently manage the computational resources for video analytics~\cite{jain2020spatula,zhang2017live,jiang2018chameleon,201465videostorm}. Chameleon, presented in~\cite{jiang2018chameleon}, frequently reconfigures the placement of video analytics pipelines to reduce resource consumption with small loss in accuracy. Another example is Spatula~\cite{jain2020spatula}, which exploits the spatial and temporal correlations among different camera flows to reduce the network and computation costs. However, such solutions only consider video flows coming from fixed cameras.


\paragraph{Deployment strategies.} 
Other solutions mainly focused on the deployment strategies of video analytics applications~\cite{zeng2020distream,201465videostorm,rachuri2021decentralized}. Distream~\cite{zeng2020distream} is a distributed framework based capable of adapting to workload dynamics to achieve low-latency, high-throughput and scalable live video analytics. Pipelines are deployed on both the smart cameras and the edge, and are jointly partitioned so that part is computed on the smart cameras, while the rest is sent towards the edge, which has more computing power at its disposal. The deployment of application pipelines is adapted to the varying processing load, however there is a lack of adaptability required by the rate of mobile cameras.
The work in~\cite{rachuri2021decentralized} presents experimental results showing that smartly distributing and processing vision modules in parallel across available edge compute nodes, can ultimately lead to better resource utilization and improved performance. The same approach is also used by VideoStorm~\cite{201465videostorm} which places different video functions across multiple available workers to satisfy users' requests. We assume a deployment of pipelines in line with this latter work given the higher flexibility, higher scalability and the better use of resources of this approach. 

\paragraph{Load balancing strategies.} Once video analytics applications have been deployed on a distributed edge infrastructure, load balancing strategies play a fundamental role in guaranteeing requirements of accuracy and efficiency. As a result, The concept of implementing load balancing for video analytics applications has gained popularity, particularly with the emergence of edge video analytics and its associated limitations. Historically, load balancing was performed between edge nodes and central clouds (\eg, VideoStorm~\cite{201465videostorm}), but this method became impractical due to increased network traffic and potential network bottlenecks. Load balancing between edge locations has been the subject of several works, including Spatula~\cite{jain2020spatula}, Hetero-edge~\cite{zhang2019hetero}, and VideoEdge~\cite{hung2018videoedge} (albeit VideoEdge still relies on offloading to remote clouds). However, these works focused on the production of static configurations, where each processed video is directed to a predetermined path through the deployed processing functions. As any change of configuration impacts the deployed functions, configuration updates occur over longer timescales, making these approaches unsuitable for highly variable loads. More recently, Distream~\cite{zeng2020distream} recognized the need for rapidly adapting to varying loads within a video, proposing an adaptable load balancing solution that splits the load balancing decisions at the pipeline level. However, it assumes that workflows present predictable longer-term patterns, allowing reconfiguration decisions only to be taken at longer timescales, for example when traffic conditions change during the day due to commute patterns.


\paragraph{Workload prediction.} Workload predictions, based on machine learning models, have been proved to be effective in the design of load balancing policies%Some approaches use machine learning models for forecasting the future workload which they then use to perform load balancing
~\cite{heinze2014auto,gedik2013elastic,kombi2017preventive,zeng2020distream}. In~\cite{yuan2021online}, authors used reinforcement learning for performing real-time estimation for dynamic assigning task to the optimal server. While the work in~\cite{kombi2017preventive}, focused on load forecasting by using linear regression model. However, reinforcement learning solution, even though effective, require a significant amount of resources and continuous online training to avoid concept-drift problems~\cite{zhang2020reinforcement}. Such a solution method is not suitable for the computational-constrained devices at the edge. In addition, the rapid changes in scenes captured by mobile cameras are more difficult to predict. Therefore, there is a need of lightweight forecasting models that can predict short-term trends, suitable for edge devices and fast enough for real-time prediction.