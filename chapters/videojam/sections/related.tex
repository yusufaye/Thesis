\section{Related work}

%\sj{This section is also very long. And a lot of it has already been covered in the Background and Motivation section.}
% \fb{This section has to be completely re-written. Start by talking about video analytics in general and how they are a topic that has been tackled from different perspectives, from the data processing architecture~\cite{jain2020spatula,zhang2017live,jiang2018chameleon}, to the processing efficiency~\cite{fouladi2017encoding,chen2015glimpse,padmanabhan2021towards,padmanabhan2023gemel}, the accuracy of the vision models~\cite{bhardwaj2022ekya,xiao2021towards,lv2023detrs}, the methodology to query the data~\cite{hsieh2018focus,cangialosi2022privid,zhangvulcan}, and the privacy of the extracted data~\cite{cangialosi2022privid,poddar2020visor,wu2021pecam}. Then move to what is relevant to us, \ie, edge based video analytics~\cite{zhang2019hetero,hung2018videoedge,wang2018bandwidth,zeng2020distream}. Structure the discussion in paragraphs, each with its own header. For example, one paragraph can be about the different architectures that have been proposed for edge based video analytics, another about the different load balancing strategies, another about the different scheduling strategies, and so on.}
In recent years, several techniques have been developed to improve the performance of video analytics applications~\cite{ibrahim2021survey,xu2023edge,hu2023edge}. Such a topic has been tackled from different perspectives, including the design of different data processing architectures~\cite{jain2020spatula,zhang2017live,jiang2018chameleon}, the improvement of pipelines' processing~\cite{fouladi2017encoding,chen2015glimpse,padmanabhan2021towards,padmanabhan2023gemel} and the privacy of the extracted data~\cite{cangialosi2022privid,poddar2020visor,wu2021pecam}. 

\paragraph{Architecture scaling.} Different approaches have been proposed to efficiently manage the computational resources for video analytics~\cite{jain2020spatula,zhang2017live,jiang2018chameleon,201465videostorm}. Chameleon, presented in~\cite{jiang2018chameleon}, frequently reconfigures the placement of video analytics pipelines to reduce resource consumption with small loss in accuracy. Another example is Spatula~\cite{jain2020spatula}, which exploits the spatial and temporal correlations among different camera flows to reduce the network and computation costs. However, such solutions only consider video flows coming from fixed cameras.


\paragraph{Deployment strategies.} 
Other solutions mainly focused on the deployment strategies of video analytics applications~\cite{zeng2020distream,201465videostorm,10.1145/3477083.3480153}. Distream~\cite{zeng2020distream} is a distributed framework based capable of adapting to workload dynamics to achieve low-latency, high-throughput and scalable live video analytics. Pipelines are deployed on both the smart cameras and the edge, and are jointly partitioned so that part is computed on the smart cameras, while the rest is sent towards the edge, which has more computing power at its disposal. The deployment of application pipelines is adapted to the varying processing load, however there is a lack of adaptability required by the rate of mobile cameras.
%However, scalability is only taken into account by the number of smart cameras and there is no information on the scalability of the edge, which contains all the components that decide on the cross-workload policy and partitioning mechanism. When the link between the smart cameras and the edge is interrupted, or when the edge fails, the whole architecture is practically down, with no way of updating the workload imbalance between the cameras and the DAG partition. Meanwhile, i
The work in~\cite{10.1145/3477083.3480153} presents experimental results showing that smartly distributing and processing vision modules in parallel across available edge compute nodes, can ultimately lead to better resource utilization and improved performance. The same approach is also used by VideoStorm~\cite{201465videostorm} which places different video functions across multiple available workers to satisfy users' requests. We assume a deployment of pipelines in line with this latter work given the higher flexibility, higher scalability and the better use of resources of this approach. 

\paragraph{Load balancing strategies.} Once video analytics applications have been deployed on a distributed edge infrastructure, load balancing strategies play a fundamental role in guaranteeing requirements of accuracy and efficiency. As a result, The concept of implementing load balancing for video analytics applications has gained popularity, particularly with the emergence of edge video analytics and its associated limitations. Historically, load balancing was performed between edge nodes and central clouds (\eg, VideoStorm~\cite{201465videostorm}), but this method became impractical due to increased network traffic and potential network bottlenecks. Load balancing between edge locations has been the subject of several works, including Spatula~\cite{jain2020spatula}, Hetero-edge~\cite{zhang2019hetero}, and VideoEdge~\cite{hung2018videoedge} (albeit VideoEdge still relies on offloading to remote clouds). However, these works focused on the production of static configurations, where each processed video is directed to a predetermined path through the deployed processing functions. As any change of configuration impacts the deployed functions, configuration updates occur over longer timescales, making these approaches unsuitable for highly variable loads. More recently, Distream~\cite{zeng2020distream} recognized the need for rapidly adapting to varying loads within a video, proposing an adaptable load balancing solution that splits the load balancing decisions at the pipeline level. However, it assumes that workflows present predictable longer-term patterns, allowing reconfiguration decisions only to be taken at longer timescales, for example when traffic conditions change during the day due to commute patterns.


\paragraph{Workload prediction.} Workload predictions, based on machine learning models, have been proved to be effective in the design of load balancing policies%Some approaches use machine learning models for forecasting the future workload which they then use to perform load balancing
~\cite{10.1145/2611286.2611314,gedik2013elastic,kombi2017preventive,zeng2020distream}. In~\cite{yuan2021online}, authors used reinforcement learning for performing real-time estimation for dynamic assigning task to the optimal server. While the work in~\cite{kombi2017preventive}, focused on load forecasting by using linear regression model. However, reinforcement learning solution, even though effective, require a significant amount of resources and continuous online training to avoid concept-drift problems~\cite{zhang2020reinforcement}. Such a solution method is not suitable for the computational-constrained devices at the edge. In addition, the rapid changes in scenes captured by mobile cameras are more difficult to predict. Therefore, there is a need of lightweight forecasting models that can predict short-term trends, suitable for edge devices and fast enough for real-time prediction.

%\ff{For the aforementioned reasons, our approach will rely on both thresholds and lightweight machine learning model to react to and predict fluctuations in workload. Whereas the threshold is based on actual load, the machine learning model uses past workload to predict future. In this way, we leverage both the reactive and the preventive approach, so that we can predict the near future workload and be warned whenever this value no longer seems to correspond to the actual load above a certain threshold.}


% In~\cite{chen2021recent}, they developed a collaborative scheduling algorithm to leverage collaboration between the cloud center, edge servers, and edge devices based on the characteristics of computing tasks, optimization goals, and system state to effectively reduce the load on edge servers, improve resource utilization, and reduce the average completion time of computing tasks in a system. However, their approach differs from ours in that the load balancer itself is distributed across each edge and is not just a component that performs collaborative load balancing across edges. In addition, offloading tasks to an edge scheduler that then determines the appropriate edge for computation can result in increased bandwidth usage and even a round trip if the origin point happens to be the least loaded, resulting in wasted time and resources.

% Alternative offloading solutions focus on task placement by determining the cost of each task over the entire pipeline~\cite{10.1016/j.comnet.2021.108361,ahn2019novel}. These take subtask dependencies into account when making scheduling decisions. However, subtask dependencies in some applications cannot be known in advance as they depend on the outcome in the early stages of the pipeline. As a result, these approaches are not suitable for unpredicted workloads.

% In addition to the load balancing mechanism, the question of when offloading or load balancing is decided also plays an important role. We know that the workload at each level of the pipeline is likely to change over time, due to multiple factors. Knowing when to react to or prevent these changes is a major challenge. In fact, some studies are focusing more on developing methods to react quickly to workload changes~\cite{10.1145/2611286.2611314, gedik2013elastic}. For instance, if the workload increases beyond a certain threshold, load balancing is triggered.\\
% On the other hand, some use techniques to prevent overload problems by forecasting the evolution of the workload and thus take decisions for the future~\cite{10.1145/2611286.2611314, gedik2013elastic, kombi2017preventive,zeng2020distream}.

% \cite{kombi2017preventive} focuses on load forecasting to decide on load distribution in the future. However, the size of the monitoring window is not easy to figure out and the forecasting model. Indeed, most existing methods monitor system performance over one or more window intervals. However, one of the main problems encountered in video analytics is the variability of the load, which depends on the content of each frame over time \Cref{fig:workload_varations}. This variability can vary depending on the target area, target object images, time, etc.~\cite{zhang2018ffs}. Even if the frames are highly correlated, it is not easy to obtain the short-term load for a quick decision such as changing scheduling policy or model configuration. The monitoring interval plays an important since, if it's long, it can lead to poor prediction when the load changes rapidly in the space of a second across windows. On the other hand, a short window will waste resources, such as the CPU, if no change is observed during the time interval and the monitor continues to measure the same performance. This aspect must be taken into account when designing an efficient architecture on system where the workload doesn't have a specific pattern.

