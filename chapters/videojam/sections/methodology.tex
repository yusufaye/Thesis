\section{Methodology}\label{sec:methodology}

Our methodology was thought so that at least the three following elements are taken in account:
\begin{enumerate}
    \item \textbf{fully distributed}: each scheduler is responsible for its own area
    \item \textbf{fault tolerance}: a node crash should not affect the system in the time it takes to detect it
    \item \textbf{fast}: the time needed to calculate and make a decision about load redistribution in an efficient and consistent manner should be small so as not to add any delay.
\end{enumerate}

Below, can be found a thorough description of our solution.

\subsection{The principle of workload distribution}

With the development of connected objects, data production has exploded. Processing this data in a distributed way across several computing resources has become a key factor in increasing throughput and minimizing execution time. A number of load scheduling algorithms have been proposed to optimize load distribution across devices for parallel execution. There are all kinds, depending on the use case, the architecture on which it will be employed, the communication and resource heterogeneity and constraints between the distributed resources and so on~\cite{ghomi2017load, mishra2020load, pourghebleh2020comprehensive, kaur2015review}. Above all, its purpose is to satisfy a number of requirements, such as fault tolerance, throughput maximization and execution time minimization~\cite{kaur2015review}.

When it comes to workload distribution, many questions can be raised about the policies to be applied. It is therefore necessary to model the choice of constraints in order to implement the model that works best. For example, when resources are heterogeneous, a fair distribution would not only be in terms of amount of load, but also processing power. The propagation delay of workload must also be taken into account with the network bandwidth and latency constraints for real-time application. In addition, fault tolerance also plays a central role in these types of systems. What happens if a resource fails, or the component responsible for the scheduling policy fails?





The main goal we wish to achieve is to make all replicas to work together and to decide how to distribute their workload from the most loaded to the least loaded, while ensuring that they all finish at approximately the same time. This naturally results in maximized throughput, minimized execution time and equal process occupancy.

At the difference from the existent, the load balancer is not seen as reverse proxy which is responsible for monitoring performance, \eg, current load a and processing rate, in order to distribute the workload across number of replicas.\\
In contrast, each replicas will be attached to small component which will be responsible for monitoring performance. All schedulers will then communicate with its performance to its neighbors. So they can easily compute the offloading policy based upon this information.\\
As a result, our proposed solution guarantee totally flexible and fault-tolerant as each neighbor can arrive and leave at any time. This is a new way of approaching workload dispatching across replicas in instable environment as edges with multiple limitations.

In addition, our approach leverage both the reactive and the preventive approach, so that it can forecasting the near future workload and be notified whenever this value no longer matches to the actual load since with mobile cameras workload changes very often. Whereas the threshold is based on actual load, the machine learning model uses past workload to predict future.


\subsection{The load balancing}

As explained previously, in our approach there is no central component for deciding how instances can offload their overloaded task to others less loaded. In contrast, the scheduler itself is assigned or attached at the same local as the instance (or group of instances) that it is responsible for. Then each scheduler performs some monitoring. The incoming workload is determined by the monitoring over multiple interval of time and then shared across neighbors. The \Cref{sec:architecture} will go deep in details on the functioning.\\
In addition to the incoming workload, the scheduler can also determine the queue size of each replicas that it is responsible for and their processing capacity. This information is shared to each other.

Our goal is therefore to make all to minimize to completion time and increase the throughput. Therefore, the question we can ask ourselves is: where will the load distribution be calculated? Is it at the level of the scheduler who wants to reduce his load or at the one that can be requested to receive one?\\
In the first case, we will have to take into account the decision of each scheduler when determining the load we want to send to each of them. Such consideration adds more complexity to solving the equation so that the load can be distributed fairly among the schedulers. In contrast, letting a scheduler decide how much load it can receive from each scheduler individually is more reasonable and easier to implement.

At that stage, each scheduler performs the following steps below for dispatching load:
\begin{enumerate}
    \item forecasting the near-future workload,
    \item next computes the balanced workload for each scheduler according to its performance and its neighbors and their states,
    \item then it computes the maximum load that the less overloaded should receive from others (more overloaded) a limit of a certain amount.
\end{enumerate}

At this point, one might wonder how the schedulers are going to decide how loads are to be distributed between them. Should each scheduler calculate the load it can receive and impose it on everyone else? Or should the others determine how much they can send?
The former would seem more logical. But let's not forget that each scheduler determines the load distribution according to the information it has from its neighbors, which is subject to change over time. The same applies to the second case.

Therefore, the best way is to let all the schedulers determine the different load movements that each neighbor should handle. And if, however, these values do not agree during the offloading phase, between the two schedulers that have to exchange loads, they can then correct each other and adapt their scheduling policy.

Details of how our approach works are given in the next section.