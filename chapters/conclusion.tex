\setchapterpreamble[u]{\margintoc}
\chapter{Conclusion}
\labch{conclusion}

In conclusion, this thesis has presented two main contributions in the field of video analytics on distributed cloud platforms at the edge. We have introduced a new load balancing approach that adapts to heterogeneous camera sources, including fixed and mobile inputs. Furthermore, we developed a fine-grained model placement strategy that takes into account low-level GPU operations and proactively addresses interference between models. The remainder of this section revisits the central research question, summarizes our proposed solutions, discusses the limitations of our work, and offers recommendations for future research directions.

\section{Research Problem and Summary of Contributions}

We have discussed in this manuscript some issues related to live video analytics and, more importantly, when dealing with resource-constrained infrastructures. In Chapter 3, we discussed the many fields of research and application of edge-cloud computing, particularly video analytics applications, which are beginning to show their presence and importance in today's society. In this thesis, we have focused on two key points in particular: challenges to balancing computational demands, distributing video workloads across edge nodes with the integration of mobile cameras, and the deployment of deep neural network (DNN) models in resource-constrained environments, where the co-location of multiple computing tasks is often required.


Our first contribution, presented in Chapter 4, identifies critical limitations in integrating mobile cameras with edge computing, primarily due to their unpredictable availability and dynamic movement, which compromise background subtractor and lead to unreliable object detection. These constraints are further exacerbated by fluctuating workloads and the need for rapid reconfiguration of processing pipelines as mobile cameras join or leave the network. To address these challenges, we introduce Videjam, a novel system designed to integrate heterogeneous camera sources, both fixed and mobile, while maintaining low-latency performance. Videjam incorporates short-term load prediction and function-level load balancing to manage high variability in computational demand. Empirical evaluations demonstrate that Videjam achieves 2.91× lower response times, reduces video data loss by over 4.64×, and minimizes bandwidth overhead, thereby enabling a more adaptive and resilient video analytics architecture.

In the second part of our work, presented in Chapter 5, we examine deployment strategies for deep neural networks (DNNs) in resource-constrained edge environments, particularly in mandatory co-location scenarios. Although many approaches have been proposed to optimize inference performance, most remain reactive, focusing on post-deployment planning or coarse profiling, and often fail to anticipate interference between models sharing GPU resources. These methods typically neglect the fine-grained execution characteristics of DNNs and rely on cloud-centric infrastructure, limiting their applicability to edge platforms. To address these shortcomings, we introduce Roomie, a kernel-aware orchestration system that profiles GPU kernel execution sequences to accurately model interference patterns. By leveraging these profiles, Roomie intelligently manages model placement, scheduling, and resource allocation across edge clusters. Experimental results demonstrate that Roomie significantly improves overall throughput compared to state-of-the-art systems.

\section{Limitations}

While VideoJam and Roomie successfully address key challenges related to edge video analysis and deep neural network deployment, both systems have limitations that leave room for improvement and further research.
VideoJam does not take into account the bandwidths of inter-functional links when determining load balancing policies. In heterogeneous network environments, where link speeds vary significantly, this omission can adversely affect the overall efficiency of the system. Furthermore, VideoJam operates independently of the underlying deployment configuration (\eg, the number of function replicas), but it lacks mechanisms to handle overload scenarios in which incoming video sources exceed available processing capacity. Moreover, VideoJam treats functions with similar objectives but different implementations (\eg, YOLOv5 vs. SSD) as identical entities, overlooking critical differences in accuracy, model size, and inference latency, factors that could significantly impact resource planning and allocation.

Roomie, on the other hand, faces scalability constraints, as its convergence time increases with the number of DNNs considered for interference. This poses challenges for real-time applications that require rapid adaptation. Furthermore, Roomie's current approach to profiling focuses primarily on kernel-level parameters, such as thread block size, shared memory, register usage, and occupancy. Its design does not yet incorporate a broader set of system-level factors that influence execution behavior, including PCIe bandwidth, L1/L2 cache performance, the number of streaming multiprocessors (SMs) available to the GPU, and interleave latency between cores. These parameters, while less directly related to the core configuration at launch, play a crucial role in interference dynamics and overall system responsiveness.

Overall, these limitations highlight areas for future research and improvement, and we plan to address them in our future work.

\section{Recommendations and Future Work}

% Après avoir constaté certaines limites des différentes solutions que nous avons proposées, nous avons quelques idées qui pourraient y remédier et éventuellement d'autres suggestions d'amélioration.

% Videjam offre une technique efficace qui équilibre efficacement la charge de travail. Dans une situation où toutes les fonctions sont surchargées, nous pourrions mettre en œuvre des fonctionnalités supplémentaires telles qu'un mécanisme d'allocation dynamique des ressources capable d'ajuster l'allocation des ressources en temps réel en fonction de l'évolution des conditions du système et des exigences des applications. De plus, l'algorithme de planification sensible aux interférences, Roomie, pourrait être utilisé par Videjam pour ces tâches afin de contribuer à une planification efficace et optimisée des DNN et de minimiser les interférences. Ces deux solutions sont très complémentaires. En tirant parti de ces solutions, nous pouvons améliorer l'efficacité et l'efficience des déploiements de DNN dans l'analyse vidéo en périphérie. En outre, la prise en compte de l'état du réseau permettrait de déterminer la meilleure politique de répartition de la charge. L'état du réseau ou la bande passante pourraient être connus durant le transfert en collectant les latences de transfert (transmission).


% On the other hand, the exponential latency of Roomie's algorithm could be minimized by using a machine learning-based model, such as the one developed by Usher to determine kernel duration. One possible initial choice would be a model that determines interference and predicts the final duration of any given kernel likely to interfere. This would then allow batch processing to be leveraged to minimize response latency. However, developing such a model could also involve multiple changes, such as collecting large configurations of interfering kernels, not to mention capturing all possible kernel overlaps.
% Another proposal would be a model that instead takes into account all model sequences at once and predicts the performance degradation for each of them. We can use LSTM networks or temporal convolutional networks (TCNs), both of which have proven effective for time series data.

Our proposed systems, VideoJam and Roomie, have made a significant contribution to edge-based video analytics, but they are not without limitations. We propose potential solutions to overcome these challenges.

VideoJam offers an efficient workload balancing technique. In a situation where all functions are overloaded, we could implement additional features such as a dynamic resource allocation mechanism that can adjust resource allocation in real-time based on changing system conditions and application requirements. Furthermore, the interference-aware scheduling algorithm, Roomie, could be used by VideoJam for these tasks to contribute to efficient and optimized DNN scheduling and minimize interference. These two solutions are highly complementary and could be integrated to improve the efficiency and effectiveness of DNN deployments in edge-based video analytics. Additionally, considering network state would enable the determination of the best load balancing policy by collecting transfer latencies (transmission) to know the available bandwidth.

To minimize the exponential latency of Roomie's algorithm, we could use a machine learning-based model, such as the one developed by Usher~\cite{shubha2024usher}, to determine kernel duration. A possible initial choice would be a model that determines interference and predicts the final duration of any given kernel likely to interfere. This would then allow batch processing to be leveraged to minimize response latency. Alternatively, a model that takes into account all model sequences at once and predicts performance degradation for each of them could be used. We could utilize Long Short-Term Memory (LSTM) or Temporal Convolutional Networks (TCNs), both of which have proven effective for time series data.

% Suggest how your work could be extended or improved.

% Propose new research questions or directions that emerged from your study.