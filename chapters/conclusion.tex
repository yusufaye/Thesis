\setchapterpreamble[u]{\margintoc}
\chapter{Conclusion}
\labch{conclusion}

In conclusion, this thesis has presented two main contributions in the field of video analytics on distributed cloud platforms at the edge. We have introduced a new load balancing approach that adapts to heterogeneous camera sources, including fixed and mobile inputs. Furthermore, we developed a fine-grained model placement strategy that takes into account low-level \acrshort{gpu} operations and proactively addresses interference between models. The remainder of this section revisits the central research question, summarizes our proposed solutions, discusses the limitations of our work, and offers recommendations for future research directions.

\section{Research Problem and Summary of Contributions}

We have discussed in this manuscript some issues related to live video analytics and, more importantly, when dealing with resource-constrained infrastructures. In~\Cref{ch:related_work}, we discussed the many fields of research and application of edge-cloud computing, particularly video analytics applications, which are beginning to show their presence and importance in today's society. In this thesis, we have focused on two key points in particular: challenges to balancing computational demands, distributing video workloads across edge nodes with the integration of mobile cameras, and the deployment of \acrfull{dnn} models in resource-constrained environments, where the co-location of multiple computing tasks is often required.


Our first contribution, presented in~\Cref{ch:videojam}, identifies critical limitations in integrating mobile cameras with edge computing, primarily due to their unpredictable availability and dynamic movement, which compromise background subtractor and lead to unreliable object detection. These constraints are further exacerbated by fluctuating workloads and the need for rapid reconfiguration of processing pipelines as mobile cameras join or leave the network. To address these challenges, we introduce {\videojam}, a novel system designed to integrate heterogeneous camera sources, both fixed and mobile, while maintaining low-latency performance. {\videojam} incorporates short-term load prediction and function-level load balancing to manage high variability in computational demand. Empirical evaluations demonstrate that {\videojam} achieves 2.91× lower response times, reduces video data loss by over 4.64×, and minimizes bandwidth overhead, thereby enabling a more adaptive and resilient video analytics architecture.

In the second part of our work, presented in~\Cref{ch:roomie}, we examine deployment strategies for \acrlong{dnn}s (\acrshort{dnn}s) in resource-constrained edge environments, particularly in mandatory co-location scenarios. Although many approaches have been proposed to optimize inference performance, most remain reactive, focusing on post-deployment planning or coarse profiling, and often fail to anticipate interference between models sharing \acrshort{gpu} resources. These methods typically neglect the fine-grained execution characteristics of \acrshort{dnn}s and rely on cloud-centric infrastructure, limiting their applicability to edge platforms. To address these shortcomings, we introduce {\roomie}, a kernel-aware orchestration system that profiles \acrshort{gpu} kernel execution sequences to accurately model interference patterns. By leveraging these profiles, {\roomie} intelligently manages model placement, scheduling, and resource allocation across edge clusters. Experimental results demonstrate that {\roomie} significantly improves overall throughput compared to state-of-the-art systems.

\section{Limitations}

While {\videojam} and {\roomie} successfully address key challenges related to edge video analysis and deep neural network deployment, both systems have limitations that leave room for improvement and further research.
{\videojam} does not take into account the bandwidths of inter-functional links when determining load balancing policies. In heterogeneous network environments, where link speeds vary significantly, this omission can adversely affect the overall efficiency of the system. Furthermore, {\videojam} operates independently of the underlying deployment configuration (\eg, the number of function replicas), but it lacks mechanisms to handle overload scenarios in which incoming video sources exceed available processing capacity. Moreover, {\videojam} treats functions with similar objectives but different implementations (\eg, YOLOv5 vs. SSD) as identical entities, overlooking critical differences in accuracy, model size, and inference latency, factors that could significantly impact resource planning and allocation.

{\roomie}, on the other hand, faces scalability constraints, as its convergence time increases with the number of \acrshort{dnn}s considered for interference. This poses challenges for real-time applications that require rapid adaptation. Furthermore, {\roomie}'s current approach to profiling focuses primarily on kernel-level parameters, such as thread block size, shared memory, register usage, and occupancy. Its design does not yet incorporate a broader set of system-level factors that influence execution behavior, including PCIe bandwidth, L1/L2 cache performance, the number of \acrlong{sm}s (\acrshort{sm}s) available to the \acrshort{gpu}, and interleave latency between cores. These parameters, while less directly related to the core configuration at launch, play a crucial role in interference dynamics and overall system responsiveness.

Overall, these limitations highlight areas for future research and improvement, and we plan to address them in our future work.

\section{Recommendations and Future Work}

Our proposed systems, {\videojam} and {\roomie}, have made a significant contribution to edge-based video analytics, but they are not without limitations. We propose potential solutions to overcome these challenges.

{\videojam} offers an efficient workload balancing technique. In a situation where all functions are overloaded, we could implement additional features such as a dynamic resource allocation mechanism that can adjust resource allocation in real-time based on changing system conditions and application requirements. Furthermore, the interference-aware scheduling algorithm, {\roomie}, could be used by {\videojam} for these tasks to contribute to efficient and optimized \acrshort{dnn} scheduling and minimize interference. These two solutions are highly complementary and could be integrated to improve the efficiency and effectiveness of \acrshort{dnn} deployments in edge-based video analytics. Additionally, considering network state would enable the determination of the best load balancing policy by collecting transfer latencies (transmission) to know the available bandwidth.

To minimize the exponential latency of {\roomie}'s algorithm, we could use a machine learning-based model, such as the one developed by Usher~\cite{shubha2024usher}, to determine kernel duration. A possible initial choice would be a model that determines interference and predicts the final duration of any given kernel likely to interfere. This would then allow batch processing to be leveraged to minimize response latency. Alternatively, a model that takes into account all model sequences at once and predicts performance degradation for each of them could be used. We could utilize \acrfull{lstm} or \acrlong{tcn} (\acrshort{tcn}s)~\cite{KerasTCN}, both of which have proven effective for time series data.

% Suggest how your work could be extended or improved.

% Propose new research questions or directions that emerged from your study.

--------

**Instance Lifecycle and Minimal Service Assignment**

A key direction for future work involves refining the lifecycle management of pipeline instances. The use of a T-second lease system for removing underutilized instances offers a simple yet effective strategy for dynamic downscaling. Building on this, we propose a classification model that distinguishes between primitive instances, which represent the minimal service assignment and are retained regardless of system state, and reserved instances, which are created through scaling and may be removed when saturation subsides or when another instance requires upscaling. This distinction enables more flexible and efficient resource allocation across pipelines.

**Preemptive Scaling and Critical Instance Identification**

To anticipate saturation and improve responsiveness, future work should explore preemptive scaling strategies. This involves identifying critical instances—such as those positioned mid-pipeline or deployed last during initial assignment—and preparing scaling opportunities before performance degradation occurs. Such proactive measures could reduce latency and improve throughput under dynamic workloads.

**Variant-Aware Deployment and Rollback Strategy**

Applications with multiple candidate variants require a deployment strategy that balances performance and adaptability. We propose selecting the best-performing variant for each application as the primitive, while treating additional variants as reserved. These reserved variants may be removed when the system is underutilized or when resources are needed elsewhere. A rollback mechanism should be integrated to monitor system performance after variant deployment and revert changes if throughput declines. This approach ensures stability while supporting adaptive optimization.

**Batch Size Adaptation and Scheduling Integration**

Following any change in a worker’s deployment, all variants enter an unstable state and must determine the optimal batch size for performance. This batch size adaptation process should be extended to the Usher component, which schedules variants to workers. Integrating adaptation into scheduling decisions will enhance responsiveness and maintain throughput during reconfiguration.

**Decentralized Load Balancing and Fault Tolerance**

The centralized load balancing mechanism currently proposed introduces a single point of failure. A decentralized alternative based on leader election would improve fault tolerance and scalability. Moreover, the existing balancing strategy adjusts only one instance per interval, which becomes inefficient as the number of instances increases. Future work should investigate parallelized adjustment mechanisms to maintain system responsiveness at scale.

**Deployment Efficiency under Resource Constraints**

The assumption that the number of edge devices exceeds the number of pipeline primitives may not hold in practice. In many scenarios, the number of functions to deploy surpasses available devices, requiring co-location and careful scheduling. Future research should explore deployment strategies that optimize performance under constrained resources, including selective activation, function prioritization, and dynamic co-location policies.