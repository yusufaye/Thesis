\setchapterpreamble[u]{\margintoc}
\chapter{Introduction}
\labch{intro}

\section{Motivation}

Over the past decade, the widespread availability of data from various sources, including camera steams, has become a ubiquitous feature in urban environments and beyond~\cite{yu2023urban,tekouabou2022identifying}. This data is increasingly being used to gather valuable insights, contributing to improved public safety, operational efficiency, and decision-making in a variety of fields. This wealth of information not only supports surveillance activities, but also plays a critical role in traffic management, crime prevention, urban planning, and other critical applications~\cite{hu2023edge,xu2023edge,xu2023mobile,hossain2018edge}. By leveraging this data, local authorities and organizations can make informed decisions that improve quality of life, safety, and optimize resource allocation.
On the other hand, the rapid transformation of artificial intelligence has made it a powerful tool that profoundly influences industries and societies. Artificial intelligence plays a crucial role in analyzing and interpreting these vast data sets, facilitating a variety of applications such as video surveillance, medical diagnostics, autonomous systems, and real-time analysis. This expansion of AI applications requires infrastructure capable of efficiently and rapidly processing large computational workloads, while offering innovative solutions to contemporary challenges.

As video data becomes increasingly central to AI-driven applications, live video analytics plays a pivotal role in extracting real-time insights from visual streams~\cite{hu2023edge,xu2023edge}. Live video analytics involves the real-time processing of camera feeds using algorithmic and computer vision techniques to derive actionable intelligence. These streams typically pass through a structured pipeline, often modeled as a directed acyclic graph, comprising sequential functions such as object detection, classification, and tracking~\cite{zeng2020distream,jiang2018chameleon,hung2018videoedge,201465videostorm}. Video analytics has become a fundamental part of intelligent automation, enabling systems to interpret and respond to visual data in real-time. Its applications span a wide range of areas, including automated traffic management, where it facilitates the detection of traffic jams and accidents, as well as surveillance, crowd control, and assisted and autonomous driving. By leveraging the growing volume of video data and the insights it provides, video analytics enables individuals and organizations to make more informed, faster, and more strategic decisions.

Traditionally, video analytics has relied heavily on cloud-based processing, where raw video streams are transmitted to centralized data centers for analysis~\cite{ao2018sprocket,zhang2017live,fouladi2017encoding}. However, this approach introduces significant limitations. The massive volume of video data generated by high-resolution cameras places immense strain on network bandwidth, leading to latency issues and potential bottlenecks~\cite{chen2015glimpse,hung2018videoedge}. These delays are especially problematic in time-sensitive scenarios such as emergency response, industrial safety, or autonomous navigation, where milliseconds matter.

To overcome these challenges, the field is increasingly shifting toward edge computing, processing data locally at or near the source~\cite{zeng2020distream,jiang2018chameleon,zhang2019hetero}. This approach reduces latency, conserves bandwidth, and enhances the responsiveness of video analytics systems. Yet, edge computing introduces its own set of constraints. Despite the presence of advanced \acrshort{gpu}s, edge devices have limited computational capacity and can quickly become overwhelmed by high-volume video streams, leading to data loss and degraded performance.

This thesis addresses two critical challenges in the design of scalable and efficient video analytics systems, each representing a distinct contribution to the field.

First, it explores the integration of mobile cameras with distributed edge computing architectures. Mobile cameras offer flexibility and dynamic coverage; however, their unpredictable nature, as they can appear and disappear at any time, requires efficient data processing to avoid longer response times. This work proposes a new approach strategy for distributing video workloads across multiple edge nodes to balance computational demands, reduce latency, and improve overall system responsiveness. By optimizing data flow and task allocation, the proposed approach enhances throughput while maintaining low-latency performance a key requirement for real-time analytics.

Secondly, this research examines the deployment of \acrfull{dnn} models in resource-constrained environments, such as edge devices. In these settings, the co-location of multiple computing tasks is often required; however, if not managed effectively, this can result in performance degradation and diminished model accuracy. This study offers new insights into the efficient placement and execution of \acrshort{dnn} components within these environments, ensuring that analytics pipelines maintain both accuracy and responsiveness despite stringent resource limitations.

In summary, this thesis focuses on the integration of mobile camera systems with intelligent workload distribution strategies oriented towards the periphery and the optimization of \acrshort{dnn} deployment in resource-constrained environments. This work contributes to the advancement of scalable, highly accurate, and low-latency video analysis systems.
It addresses the placement problem, namely the challenge of determining the optimal deployment locations for \acrshort{dnn} functions in video analysis pipelines, taking into account resource constraints and heterogeneous camera workloads.

\section{Challenges in Incorporating Mobile Cameras}

Mobile cameras offer a dynamic and flexible viewpoint for video analytics, capturing scenes that fixed cameras might miss due to their static nature. However, this mobility poses significant challenges for video analytics architectures, especially when both types of cameras coexist in a deployment. The first major challenge lies in the heterogeneous performance profiles of processing pipelines. Fixed cameras benefit from stable backgrounds, which allow for effective object isolation using background subtraction. Mobile cameras, on the other hand, constantly change scenes, making background subtraction unreliable and often leading to false detections. To address this, mobile camera pipelines often rely on single-pass object recognition models such as YOLO, which, while more consistent, are also more resource-intensive. This divergence in processing requirements underscores the importance of tailoring analysis pipelines to the specific camera type.

The second challenge involves managing highly variable workloads. Traditional workload balancing strategies rely on predictable patterns based on camera location and time of day. Distream~\cite{zeng2020distream}'s architecture attempts to optimize workload distribution using cross-device balancing and adaptive controllers. However, mobile cameras disrupt these assumptions by introducing unpredictable scene changes and intermittent presence in the network, making long-term prediction models ineffective. The third challenge centers on deployment configuration flexibility. Fixed camera setups typically allow for slow, deliberate changes based on long-term usage patterns. Mobile cameras, however, demand real-time adaptability, as they can join or leave the network at any moment. This necessitates an online load balancing system capable of reconfiguring processing pipelines within seconds, without requiring full system reboots. Together, these challenges highlight the need for a fundamentally more agile and responsive video analytics architecture.

\section{Deployment Challenges on Edge-Cloud Devices}

Optimizing resource utilization in edge computing environments, such as mobile platforms, low-power nodes, or remote devices, requires a modular approach to AI deployment. Decoupling the processing pipeline into separate functions (\eg, background subtraction, object detection, tracking, and classification), as in live video analytics, allows each stage to process data independently and pass results downstream, providing greater flexibility and efficiency. However, due to the limited computing and energy resources available in these environments, colocating multiple AI models on shared hardware often becomes a necessity to meet real-time performance requirements and reduce deployment costs. This pragmatic choice, while effective in theory, introduces a series of challenges: resource contention, interference between models, and degradation of quality of service metrics. Existing solutions often overlook these dynamics, deploying entire pipelines on single devices or distributing them without considering the negative interactions between co-deployed models. To mitigate these risks and ensure fair, predictable, and high-performance AI inference, sophisticated planning and optimization strategies are essential.

A fundamental first step in this process is to recognize and measure interference between co-deployed models before assigning them to a target \acrshort{gpu} resource. By doing so, we can strategically deploy functions across available resources, maximizing the efficiency of edge devices. This requires a good understanding of how the \acrshort{gpu} execution model works during inference. Such an understanding hinges on grasping the internal mechanics of \acrshort{gpu} architecture. Designed to manage intensive workloads, \acrshort{gpu}s rely on a highly parallel structure made up of multiple \acrlong{sm}s (\acrshort{sm}), each with its own set of processing cores, registers, and shared memory. This configuration enables \acrshort{gpu}s to excel at the training and inference tasks central to \acrfull{ml} and \acrfull{dnn}.

Frameworks like \acrfull{cuda} and \acrfull{opencl} have enhanced \acrshort{gpu} utility by offering granular control over kernel execution, memory access, and thread parallelism. \acrshort{cuda}, in particular, has become the standard for programming NVIDIA \acrshort{gpu}s, enabling researchers and engineers to harness low-level optimization capabilities and achieve breakthrough AI performance. However, understanding how kernels are scheduled and executed in the \acrshort{gpu} during inference is crucial. Once deployed, each model will execute several kernels successively, where each kernel requires a certain amount of register allocation, shared memory, and warps to run efficiently. This low-level view complements high-level planning strategies, enabling smarter placement of models, particularly in edge environments where resource constraints necessitate the co-deployment of \acrlong{dnn}s (\acrshort{dnn}s).



\section{Contributions of this Thesis}

This thesis aims to introduce and design an innovative architecture tailored to the aforementioned challenges associated with deploying video analytics applications in resource-constrained environments. The proposed framework will establish efficient methods for distributing and managing processing pipelines to adapt to fluctuating workloads. By optimizing resource efficiency and streamlining task distribution, we will be able to improve the overall performance and reliability of video analytics systems in varied and constantly evolving scenarios.

This thesis presents several significant contributions to the fields of edge computing and video analytics:

\paragraph{Self-Balancing Architecture for Live Video Analytics.} {\videojam} implements a distributed load balancing system by deploying load balancers colocated with each task in the analytics pipeline. Each load balancer continuously monitors the incoming flow of frames or objects and periodically shares this information with neighboring load balancers. Based on the collected data, each load balancer independently decides how much traffic to process locally and whether to offload some of its workload to less-burdened neighbors using a lightweight machine learning model that predicts the incoming workload for each processing component and its neighbors in the near future. Additionally, the load balancers employ a congestion prevention signaling system to correct any prediction errors. {\videojam} operates autonomously, adapting dynamically to changes such as new camera arrivals or departures without requiring system reboots, and balances incoming traffic accordingly. Our approach uniquely combines horizontal distribution and per-function type load balancing, driven by short-term forecasts of incoming loads.

\paragraph{Efficient Model Cohabitation in Edge Computing Model Serving.} An orchestration architecture designed to maximize system performance in scenarios where model colocation is necessary, particularly in resource-constrained edge environments. The key innovation of {\roomie} is its kernel-aware interference profiling, which captures the sequential nature of \acrshort{gpu} kernel execution patterns when multiple models share hardware resources. By analyzing how specific kernel sequences from different models interact, {\roomie} constructs accurate interference profiles that predict performance degradation under various colocation scenarios. This detailed approach allows {\roomie} to make optimal placement decisions, determining which models can efficiently coexist on the same hardware and which combinations should be avoided to ensure performance guarantees.

Building upon these contributions, the next chapter (\Cref{ch:related_work}) will explore the foundational background and relevant literature that inform our research. This contextual groundwork is essential for grasping the significance of our innovations and the methodological choices made throughout the thesis, thereby enabling a holistic understanding of our strategy for optimizing edge computing and video analytics.